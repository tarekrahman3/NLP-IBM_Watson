<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="format-detection" content="telephone=no">
    <meta name="format-detection" content="address=no">
    <link rel="icon" id="favicon" type="image/x-icon" href="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg">
    <link rel="apple-touch-icon" href="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg">
    <link rel="apple-touch-icon" sizes="76x76" href="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg">
    <link rel="apple-touch-icon" sizes="114x114" href="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg">
    <link rel="apple-touch-icon" sizes="144x144" href="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.0/animate.min.css">
    
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.9.0/slick.css">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.9.0/slick-theme.min.css">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.2/css/all.min.css" integrity="sha256-BtbhCIbtfeVWGsqxk1vOHEYXS6qcvQvLMZqjtpWUEx8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/css/main.min.css?v=1.9.1.2">
    <link rel="stylesheet" href="https://automation.analyticsvidhya.com/static/css/stripBootstrap.css">
    <script async="" src="https://connect.facebook.net/en_US/fbevents.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://snap.licdn.com/li.lms-analytics/insight.min.js"></script><script type="text/javascript" async="" src="//www.googleadservices.com/pagead/conversion_async.js"></script><script async="" src="https://www.googletagmanager.com/gtm.js?id=GTM-MPSM42V"></script><script src="https://code.jquery.com/jquery-3.5.1.min.js" type="text/javascript"></script>
    <title>What is Tokenization | Methods to Perform Tokenization</title>
    
    <script type="text/javascript">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-MPSM42V');</script>
    
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MPSM42V"
        height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    
    
    <script type="text/javascript">
        (function(h,o,t,j,a,r){
            h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
            h._hjSettings={hjid:2707761,hjsv:6};
            a=o.getElementsByTagName('head')[0];
            r=o.createElement('script');r.async=1;
            r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
            a.appendChild(r);
        })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
        </script>
    <style>
    .stb-container-css {margin: 10px 10px 10px 10px;}.stb-box {}.stb-caption-box {}.stb-body-box {}
    /* Class Dependent Parameters */
    .stb-border.stb-alert-container {border: 1px none #FF4F4A;}.stb-side.stb-alert-container {background: #FF4F4A;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FF4F4A', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #FF4F4A 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FF4F4A), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: -o-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: -ms-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: linear-gradient(#FF4F4A 30%, #504848 90%);}.stb-side-none.stb-alert-container {background: #FFE7E6;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FFE7E6', endColorstr='#fb7d78',GradientType=0 );background: -moz-linear-gradient(top,  #FFE7E6 30%, #fb7d78 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FFE7E6), color-stop(90%,#fb7d78));background: -webkit-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -o-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -ms-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: linear-gradient(#FFE7E6 30%, #fb7d78 90%);}.stb-alert_box {background: #FFE7E6;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FFE7E6', endColorstr='#fb7d78',GradientType=0 );background: -moz-linear-gradient(top,  #FFE7E6 30%, #fb7d78 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FFE7E6), color-stop(90%,#fb7d78));background: -webkit-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -o-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -ms-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: linear-gradient(#FFE7E6 30%, #fb7d78 90%);color: #000000;}.stb-alert-caption_box {background: #FF4F4A;background: -moz-linear-gradient(top,  #FF4F4A 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FF4F4A), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: -o-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: -ms-linear-gradient(top,  #FF4F4A 30%,#504848 90%);background: linear-gradient(#FF4F4A 30%, #504848 90%);color: #FFFFFF;}.stb-alert-body_box {background: #FFE7E6;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FFE7E6', endColorstr='#fb7d78',GradientType=0 );background: -moz-linear-gradient(top,  #FFE7E6 30%, #fb7d78 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FFE7E6), color-stop(90%,#fb7d78));background: -webkit-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -o-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: -ms-linear-gradient(top,  #FFE7E6 30%,#fb7d78 90%);background: linear-gradient(#FFE7E6 30%, #fb7d78 90%);color: #000000;}.stb-border.stb-black-container {border: 1px none #6E6E6E;}.stb-side.stb-black-container {background: #333333;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#333333', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #333333 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#333333), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #333333 30%,#504848 90%);background: -o-linear-gradient(top,  #333333 30%,#504848 90%);background: -ms-linear-gradient(top,  #333333 30%,#504848 90%);background: linear-gradient(#333333 30%, #504848 90%);}.stb-side-none.stb-black-container {background: #000000;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#000000', endColorstr='#000000',GradientType=0 );background: -moz-linear-gradient(top,  #000000 30%, #000000 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#000000), color-stop(90%,#000000));background: -webkit-linear-gradient(top,  #000000 30%,#000000 90%);background: -o-linear-gradient(top,  #000000 30%,#000000 90%);background: -ms-linear-gradient(top,  #000000 30%,#000000 90%);background: linear-gradient(#000000 30%, #000000 90%);}.stb-black_box {background: #000000;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#000000', endColorstr='#000000',GradientType=0 );background: -moz-linear-gradient(top,  #000000 30%, #000000 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#000000), color-stop(90%,#000000));background: -webkit-linear-gradient(top,  #000000 30%,#000000 90%);background: -o-linear-gradient(top,  #000000 30%,#000000 90%);background: -ms-linear-gradient(top,  #000000 30%,#000000 90%);background: linear-gradient(#000000 30%, #000000 90%);color: #FFFFFF;}.stb-black-caption_box {background: #333333;background: -moz-linear-gradient(top,  #333333 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#333333), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #333333 30%,#504848 90%);background: -o-linear-gradient(top,  #333333 30%,#504848 90%);background: -ms-linear-gradient(top,  #333333 30%,#504848 90%);background: linear-gradient(#333333 30%, #504848 90%);color: #FFFFFF;}.stb-black-body_box {background: #000000;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#000000', endColorstr='#000000',GradientType=0 );background: -moz-linear-gradient(top,  #000000 30%, #000000 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#000000), color-stop(90%,#000000));background: -webkit-linear-gradient(top,  #000000 30%,#000000 90%);background: -o-linear-gradient(top,  #000000 30%,#000000 90%);background: -ms-linear-gradient(top,  #000000 30%,#000000 90%);background: linear-gradient(#000000 30%, #000000 90%);color: #FFFFFF;}.stb-border.stb-custom-container {border: 1px none #f844ee;}.stb-side.stb-custom-container {background: #f844ee;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#f844ee', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #f844ee 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#f844ee), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #f844ee 30%,#504848 90%);background: -o-linear-gradient(top,  #f844ee 30%,#504848 90%);background: -ms-linear-gradient(top,  #f844ee 30%,#504848 90%);background: linear-gradient(#f844ee 30%, #504848 90%);}.stb-side-none.stb-custom-container {background: #f7cdf5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#f7cdf5', endColorstr='#f77df1',GradientType=0 );background: -moz-linear-gradient(top,  #f7cdf5 30%, #f77df1 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#f7cdf5), color-stop(90%,#f77df1));background: -webkit-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -o-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -ms-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: linear-gradient(#f7cdf5 30%, #f77df1 90%);}.stb-custom_box {background: #f7cdf5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#f7cdf5', endColorstr='#f77df1',GradientType=0 );background: -moz-linear-gradient(top,  #f7cdf5 30%, #f77df1 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#f7cdf5), color-stop(90%,#f77df1));background: -webkit-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -o-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -ms-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: linear-gradient(#f7cdf5 30%, #f77df1 90%);color: #000000;}.stb-custom-caption_box {background: #f844ee;background: -moz-linear-gradient(top,  #f844ee 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#f844ee), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #f844ee 30%,#504848 90%);background: -o-linear-gradient(top,  #f844ee 30%,#504848 90%);background: -ms-linear-gradient(top,  #f844ee 30%,#504848 90%);background: linear-gradient(#f844ee 30%, #504848 90%);color: #ffffff;}.stb-custom-body_box {background: #f7cdf5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#f7cdf5', endColorstr='#f77df1',GradientType=0 );background: -moz-linear-gradient(top,  #f7cdf5 30%, #f77df1 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#f7cdf5), color-stop(90%,#f77df1));background: -webkit-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -o-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: -ms-linear-gradient(top,  #f7cdf5 30%,#f77df1 90%);background: linear-gradient(#f7cdf5 30%, #f77df1 90%);color: #000000;}.stb-border.stb-download-container {border: 1px none #65ADFE;}.stb-side.stb-download-container {background: #65ADFE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#65ADFE', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #65ADFE 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#65ADFE), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: -o-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: -ms-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: linear-gradient(#65ADFE 30%, #504848 90%);}.stb-side-none.stb-download-container {background: #DFF0FF;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#DFF0FF', endColorstr='#2e7cb9',GradientType=0 );background: -moz-linear-gradient(top,  #DFF0FF 30%, #2e7cb9 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#DFF0FF), color-stop(90%,#2e7cb9));background: -webkit-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -o-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -ms-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: linear-gradient(#DFF0FF 30%, #2e7cb9 90%);}.stb-download_box {background: #DFF0FF;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#DFF0FF', endColorstr='#2e7cb9',GradientType=0 );background: -moz-linear-gradient(top,  #DFF0FF 30%, #2e7cb9 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#DFF0FF), color-stop(90%,#2e7cb9));background: -webkit-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -o-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -ms-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: linear-gradient(#DFF0FF 30%, #2e7cb9 90%);color: #000000;}.stb-download-caption_box {background: #65ADFE;background: -moz-linear-gradient(top,  #65ADFE 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#65ADFE), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: -o-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: -ms-linear-gradient(top,  #65ADFE 30%,#504848 90%);background: linear-gradient(#65ADFE 30%, #504848 90%);color: #FFFFFF;}.stb-download-body_box {background: #DFF0FF;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#DFF0FF', endColorstr='#2e7cb9',GradientType=0 );background: -moz-linear-gradient(top,  #DFF0FF 30%, #2e7cb9 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#DFF0FF), color-stop(90%,#2e7cb9));background: -webkit-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -o-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: -ms-linear-gradient(top,  #DFF0FF 30%,#2e7cb9 90%);background: linear-gradient(#DFF0FF 30%, #2e7cb9 90%);color: #000000;}.stb-border.stb-grey-container {border: 1px none #BBBBBB;}.stb-side.stb-grey-container {background: #BBBBBB;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#BBBBBB', endColorstr='#6e6e6e',GradientType=0 );background: -moz-linear-gradient(top,  #BBBBBB 30%, #6e6e6e 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#BBBBBB), color-stop(90%,#6e6e6e));background: -webkit-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: -o-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: -ms-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: linear-gradient(#BBBBBB 30%, #6e6e6e 90%);}.stb-side-none.stb-grey-container {background: #EEEEEE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#EEEEEE', endColorstr='#ababab',GradientType=0 );background: -moz-linear-gradient(top,  #EEEEEE 30%, #ababab 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#EEEEEE), color-stop(90%,#ababab));background: -webkit-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -o-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -ms-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: linear-gradient(#EEEEEE 30%, #ababab 90%);}.stb-grey_box {background: #EEEEEE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#EEEEEE', endColorstr='#ababab',GradientType=0 );background: -moz-linear-gradient(top,  #EEEEEE 30%, #ababab 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#EEEEEE), color-stop(90%,#ababab));background: -webkit-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -o-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -ms-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: linear-gradient(#EEEEEE 30%, #ababab 90%);color: #000000;}.stb-grey-caption_box {background: #BBBBBB;background: -moz-linear-gradient(top,  #BBBBBB 30%, #6e6e6e 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#BBBBBB), color-stop(90%,#6e6e6e));background: -webkit-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: -o-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: -ms-linear-gradient(top,  #BBBBBB 30%,#6e6e6e 90%);background: linear-gradient(#BBBBBB 30%, #6e6e6e 90%);color: #FFFFFF;}.stb-grey-body_box {background: #EEEEEE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#EEEEEE', endColorstr='#ababab',GradientType=0 );background: -moz-linear-gradient(top,  #EEEEEE 30%, #ababab 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#EEEEEE), color-stop(90%,#ababab));background: -webkit-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -o-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: -ms-linear-gradient(top,  #EEEEEE 30%,#ababab 90%);background: linear-gradient(#EEEEEE 30%, #ababab 90%);color: #000000;}.stb-border.stb-info-container {border: 1px none #7AD975;}.stb-side.stb-info-container {background: #7AD975;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#7AD975', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #7AD975 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#7AD975), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #7AD975 30%,#504848 90%);background: -o-linear-gradient(top,  #7AD975 30%,#504848 90%);background: -ms-linear-gradient(top,  #7AD975 30%,#504848 90%);background: linear-gradient(#7AD975 30%, #504848 90%);}.stb-side-none.stb-info-container {background: #E2F8DE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#E2F8DE', endColorstr='#79b06e',GradientType=0 );background: -moz-linear-gradient(top,  #E2F8DE 30%, #79b06e 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#E2F8DE), color-stop(90%,#79b06e));background: -webkit-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -o-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -ms-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: linear-gradient(#E2F8DE 30%, #79b06e 90%);}.stb-info_box {background: #E2F8DE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#E2F8DE', endColorstr='#79b06e',GradientType=0 );background: -moz-linear-gradient(top,  #E2F8DE 30%, #79b06e 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#E2F8DE), color-stop(90%,#79b06e));background: -webkit-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -o-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -ms-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: linear-gradient(#E2F8DE 30%, #79b06e 90%);color: #000000;}.stb-info-caption_box {background: #7AD975;background: -moz-linear-gradient(top,  #7AD975 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#7AD975), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #7AD975 30%,#504848 90%);background: -o-linear-gradient(top,  #7AD975 30%,#504848 90%);background: -ms-linear-gradient(top,  #7AD975 30%,#504848 90%);background: linear-gradient(#7AD975 30%, #504848 90%);color: #FFFFFF;}.stb-info-body_box {background: #E2F8DE;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#E2F8DE', endColorstr='#79b06e',GradientType=0 );background: -moz-linear-gradient(top,  #E2F8DE 30%, #79b06e 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#E2F8DE), color-stop(90%,#79b06e));background: -webkit-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -o-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: -ms-linear-gradient(top,  #E2F8DE 30%,#79b06e 90%);background: linear-gradient(#E2F8DE 30%, #79b06e 90%);color: #000000;}.stb-border.stb-section-container {border: 1px none #2982C5;}.stb-side.stb-section-container {background: #2982C5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#2982C5', endColorstr='#2944f2',GradientType=0 );background: -moz-linear-gradient(top,  #2982C5 30%, #2944f2 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#2982C5), color-stop(90%,#2944f2));background: -webkit-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: -o-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: -ms-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: linear-gradient(#2982C5 30%, #2944f2 90%);}.stb-side-none.stb-section-container {background: #2982C5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#2982C5', endColorstr='#294ee3',GradientType=0 );background: -moz-linear-gradient(top,  #2982C5 30%, #294ee3 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#2982C5), color-stop(90%,#294ee3));background: -webkit-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -o-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -ms-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: linear-gradient(#2982C5 30%, #294ee3 90%);}.stb-section_box {background: #2982C5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#2982C5', endColorstr='#294ee3',GradientType=0 );background: -moz-linear-gradient(top,  #2982C5 30%, #294ee3 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#2982C5), color-stop(90%,#294ee3));background: -webkit-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -o-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -ms-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: linear-gradient(#2982C5 30%, #294ee3 90%);color: #000000;}.stb-section-caption_box {background: #2982C5;background: -moz-linear-gradient(top,  #2982C5 30%, #2944f2 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#2982C5), color-stop(90%,#2944f2));background: -webkit-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: -o-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: -ms-linear-gradient(top,  #2982C5 30%,#2944f2 90%);background: linear-gradient(#2982C5 30%, #2944f2 90%);color: #FFFFFF;}.stb-section-body_box {background: #2982C5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#2982C5', endColorstr='#294ee3',GradientType=0 );background: -moz-linear-gradient(top,  #2982C5 30%, #294ee3 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#2982C5), color-stop(90%,#294ee3));background: -webkit-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -o-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: -ms-linear-gradient(top,  #2982C5 30%,#294ee3 90%);background: linear-gradient(#2982C5 30%, #294ee3 90%);color: #000000;}.stb-border.stb-warning-container {border: 1px none #FE9A05;}.stb-side.stb-warning-container {background: #FE9A05;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FE9A05', endColorstr='#504848',GradientType=0 );background: -moz-linear-gradient(top,  #FE9A05 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FE9A05), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: -o-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: -ms-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: linear-gradient(#FE9A05 30%, #504848 90%);}.stb-side-none.stb-warning-container {background: #FEFFD5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FEFFD5', endColorstr='#f0d208',GradientType=0 );background: -moz-linear-gradient(top,  #FEFFD5 30%, #f0d208 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FEFFD5), color-stop(90%,#f0d208));background: -webkit-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -o-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -ms-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: linear-gradient(#FEFFD5 30%, #f0d208 90%);}.stb-warning_box {background: #FEFFD5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FEFFD5', endColorstr='#f0d208',GradientType=0 );background: -moz-linear-gradient(top,  #FEFFD5 30%, #f0d208 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FEFFD5), color-stop(90%,#f0d208));background: -webkit-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -o-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -ms-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: linear-gradient(#FEFFD5 30%, #f0d208 90%);color: #000000;}.stb-warning-caption_box {background: #FE9A05;background: -moz-linear-gradient(top,  #FE9A05 30%, #504848 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FE9A05), color-stop(90%,#504848));background: -webkit-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: -o-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: -ms-linear-gradient(top,  #FE9A05 30%,#504848 90%);background: linear-gradient(#FE9A05 30%, #504848 90%);color: #FFFFFF;}.stb-warning-body_box {background: #FEFFD5;filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#FEFFD5', endColorstr='#f0d208',GradientType=0 );background: -moz-linear-gradient(top,  #FEFFD5 30%, #f0d208 90%);background: -webkit-gradient(linear, left top, left bottom, color-stop(30%,#FEFFD5), color-stop(90%,#f0d208));background: -webkit-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -o-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: -ms-linear-gradient(top,  #FEFFD5 30%,#f0d208 90%);background: linear-gradient(#FEFFD5 30%, #f0d208 90%);color: #000000;}</style>
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    
    <meta name="description" content="Looking to get started with NLP? We take a step by step look starting with what is tokenization and methods to perform tokenization for NLP tasks.">
    <link rel="canonical" href="https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/">
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="What is Tokenization | Methods to Perform Tokenization">
    <meta property="og:description" content="Looking to get started with NLP? We take a step by step look starting with what is tokenization and methods to perform tokenization for NLP tasks.">
    <meta property="og:url" content="https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/">
    <meta property="og:site_name" content="Analytics Vidhya">
    <meta property="article:publisher" content="https://www.facebook.com/AnalyticsVidhya/">
    <meta property="article:published_time" content="2019-07-18T04:04:41+00:00">
    <meta property="article:modified_time" content="2021-07-23T10:24:08+00:00">
    <meta property="og:image" content="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg">
    <meta property="og:image:width" content="1020">
    <meta property="og:image:height" content="520">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:creator" content="@analyticsvidhya">
    <meta name="twitter:site" content="@analyticsvidhya">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Shubham Singh">
    <meta name="twitter:label2" content="Est. reading time">
    <meta name="twitter:data2" content="11 minutes">
    <script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://www.analyticsvidhya.com/#website","url":"https://www.analyticsvidhya.com/","name":"Analytics Vidhya","description":"Learn everything about Analytics","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.analyticsvidhya.com/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/#primaryimage","inLanguage":"en-US","url":"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg","contentUrl":"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg","width":1020,"height":520},{"@type":"WebPage","@id":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/#webpage","url":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/","name":"What is Tokenization | Methods to Perform Tokenization","isPartOf":{"@id":"https://www.analyticsvidhya.com/#website"},"primaryImageOfPage":{"@id":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/#primaryimage"},"datePublished":"2019-07-18T04:04:41+00:00","dateModified":"2021-07-23T10:24:08+00:00","author":{"@id":"https://www.analyticsvidhya.com/#/schema/person/b3bbd59d6fb766c4eb842b46d7a4331e"},"description":"Looking to get started with NLP? We take a step by step look starting with what is tokenization and methods to perform tokenization for NLP tasks.","breadcrumb":{"@id":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/"]}]},{"@type":"BreadcrumbList","@id":"https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://www.analyticsvidhya.com/"},{"@type":"ListItem","position":2,"name":"How to Get Started with NLP &#8211; 6 Unique Methods to Perform Tokenization"}]},{"@type":"Person","@id":"https://www.analyticsvidhya.com/#/schema/person/b3bbd59d6fb766c4eb842b46d7a4331e","name":"Shubham Singh","image":{"@type":"ImageObject","@id":"https://www.analyticsvidhya.com/#personlogo","inLanguage":"en-US","url":"https://secure.gravatar.com/avatar/d5a2295fd23e493cb615164100bcd822?s=96&d=mm&r=g","contentUrl":"https://secure.gravatar.com/avatar/d5a2295fd23e493cb615164100bcd822?s=96&d=mm&r=g","caption":"Shubham Singh"},"description":"A Data Science Enthusiast who loves reading &amp; writing about Data Science and its applications. He has done many projects in this field and his recent work include concepts like Web Scraping, NLP etc. He is a Data Science Content Strategist Intern at Analytics Vidhya. And currently pursuing BTech in Computer Science from DIT University, Dehradun.","sameAs":["https://www.linkedin.com/in/shubhamsinghss/"],"url":"https://www.analyticsvidhya.com/blog/author/shubham-singh/"}]}</script>
    
    <link rel="dns-prefetch" href="//www.analyticsvidhya.com">
    <link rel="dns-prefetch" href="//s.w.org">
    <script type="text/javascript">
                window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.1.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.1.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/www.analyticsvidhya.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.8"}};
                !function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([10084,65039,8205,55357,56613],[10084,65039,8203,55357,56613])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
            </script>
    <style type="text/css">
    img.wp-smiley,
    img.emoji {
        display: inline !important;
        border: none !important;
        box-shadow: none !important;
        height: 1em !important;
        width: 1em !important;
        margin: 0 .07em !important;
        vertical-align: -0.1em !important;
        background: none !important;
        padding: 0 !important;
    }
    </style>
    <link rel="stylesheet" id="mediaelement-css" href="https://www.analyticsvidhya.com/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.16" type="text/css" media="all">
    <link rel="stylesheet" id="wp-mediaelement-css" href="https://www.analyticsvidhya.com/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=5.8" type="text/css" media="all">
    <link rel="stylesheet" id="contact-form-7-css" href="https://www.analyticsvidhya.com/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=5.4.2" type="text/css" media="all">
    <style id="contact-form-7-inline-css" type="text/css">
    .wpcf7 .wpcf7-recaptcha iframe {margin-bottom: 0;}.wpcf7 .wpcf7-recaptcha[data-align="center"] > div {margin: 0 auto;}.wpcf7 .wpcf7-recaptcha[data-align="right"] > div {margin: 0 0 0 auto;}
    </style>
    <link rel="stylesheet" id="cookie-law-info-css" href="https://www.analyticsvidhya.com/wp-content/plugins/cookie-law-info/public/css/cookie-law-info-public.css?ver=2.0.5" type="text/css" media="all">
    <link rel="stylesheet" id="cookie-law-info-gdpr-css" href="https://www.analyticsvidhya.com/wp-content/plugins/cookie-law-info/public/css/cookie-law-info-gdpr.css?ver=2.0.5" type="text/css" media="all">
    <link rel="stylesheet" id="stbCoreCSS-css" href="https://www.analyticsvidhya.com/wp-content/plugins/wp-special-textboxes/css/stb-core.css?ver=5.9.109" type="text/css" media="all">
    <link rel="stylesheet" id="jetpack_css-css" href="https://www.analyticsvidhya.com/wp-content/plugins/jetpack/css/jetpack.css?ver=10.0" type="text/css" media="all">
    <link rel="stylesheet" id="wpss-style-css" href="https://www.analyticsvidhya.com/wp-content/plugins/wordpress-simple-survey/assets/build/css/wpss-pkg.min.css?ver=5.8" type="text/css" media="all">
    <link rel="stylesheet" id="wpss-custom-db-style-css" href="https://www.analyticsvidhya.com/wp-content/plugins/wordpress-simple-survey/assets/css/custom-performance.css?ver=5.8" type="text/css" media="all">
    <script type="text/javascript" src="https://www.analyticsvidhya.com/wp-includes/js/jquery/jquery.min.js?ver=3.6.0" id="jquery-core-js"></script>
    <script type="text/javascript" src="https://www.analyticsvidhya.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2" id="jquery-migrate-js"></script>
    <script type="text/javascript" id="cookie-law-info-js-extra">
    /* <![CDATA[ */
    var Cli_Data = {"nn_cookie_ids":[],"cookielist":[],"non_necessary_cookies":[],"ccpaEnabled":"","ccpaRegionBased":"","ccpaBarEnabled":"","strictlyEnabled":["necessary","obligatoire"],"ccpaType":"gdpr","js_blocking":"1","custom_integration":"","triggerDomRefresh":"","secure_cookies":""};
    var cli_cookiebar_settings = {"animate_speed_hide":"500","animate_speed_show":"500","background":"#f0f3f7","border":"#444","border_on":"","button_1_button_colour":"#000","button_1_button_hover":"#000000","button_1_link_colour":"#fff","button_1_as_button":"1","button_1_new_win":"","button_2_button_colour":"#333","button_2_button_hover":"#292929","button_2_link_colour":"#444","button_2_as_button":"","button_2_hidebar":"","button_3_button_colour":"#000","button_3_button_hover":"#000000","button_3_link_colour":"#fff","button_3_as_button":"1","button_3_new_win":"","button_4_button_colour":"#000","button_4_button_hover":"#000000","button_4_link_colour":"#333333","button_4_as_button":"","button_7_button_colour":"#61a229","button_7_button_hover":"#4e8221","button_7_link_colour":"#fff","button_7_as_button":"1","button_7_new_win":"","font_family":"inherit","header_fix":"1","notify_animate_hide":"1","notify_animate_show":"","notify_div_id":"#cookie-law-info-bar","notify_position_horizontal":"right","notify_position_vertical":"bottom","scroll_close":"","scroll_close_reload":"","accept_close_reload":"","reject_close_reload":"","showagain_tab":"","showagain_background":"#fff","showagain_border":"#000","showagain_div_id":"#cookie-law-info-again","showagain_x_position":"100px","text":"#000","show_once_yn":"","show_once":"10000","logging_on":"","as_popup":"","popup_overlay":"1","bar_heading_text":"","cookie_bar_as":"banner","popup_showagain_position":"bottom-right","widget_position":"left"};
    var log_object = {"ajax_url":"https:\/\/www.analyticsvidhya.com\/wp-admin\/admin-ajax.php"};
    /* ]]> */
    </script>
    <script type="text/javascript" src="https://www.analyticsvidhya.com/wp-content/plugins/cookie-law-info/public/js/cookie-law-info-public.js?ver=2.0.5" id="cookie-law-info-js"></script>
    <script type="text/javascript" src="https://www.analyticsvidhya.com/wp-content/plugins/wordpress-simple-survey/assets/build/js/wpss-pkg.min.js?ver=3.0.0" id="wpss-pkg-js"></script>
    <link rel="https://api.w.org/" href="https://www.analyticsvidhya.com/wp-json/"><link rel="alternate" type="application/json" href="https://www.analyticsvidhya.com/wp-json/wp/v2/posts/54481"><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.analyticsvidhya.com/xmlrpc.php?rsd">
    <link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://www.analyticsvidhya.com/wp-includes/wlwmanifest.xml">
    <meta name="generator" content="WordPress 5.8">
    <link rel="shortlink" href="https://www.analyticsvidhya.com/?p=54481">
    <link rel="alternate" type="application/json+oembed" href="https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F">
    <link rel="alternate" type="text/xml+oembed" href="https://www.analyticsvidhya.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F&amp;format=xml">
    <script type="text/javascript"><!--
    function powerpress_pinw(pinw_url){window.open(pinw_url, 'PowerPressPlayer','toolbar=0,status=0,resizable=1,width=460,height=320');	return false;}
    //-->
    </script>
    <script type="text/javascript">/* <![CDATA[ */ jQuery.post("https://www.analyticsvidhya.com/wp-admin/admin-ajax.php", { action: "wmp_update", id: 54481, token: "2f2466467d" }); /* ]]> */</script><link rel="canonical" href="https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/">
    <script async="" src="https://static.hotjar.com/c/hotjar-2707761.js?sv=6"></script><script src="https://www.analyticsvidhya.com/wp-includes/js/wp-emoji-release.min.js?ver=5.8" type="text/javascript" defer=""></script><link rel="stylesheet" type="text/css" media="all" href="https://www.analyticsvidhya.com/wp-content/plugins/oembed-gist/css/style.min.css?ver=4.9.1"><style id="googleidentityservice_button_styles">.qJTHM{-webkit-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:'Roboto-Regular',arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{word-break:break-all}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-uaxL4e{-webkit-border-radius:10px;border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf,.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}.P1ekSe-ZMv3u>div:nth-child(1){background-color:#1a73e8!important}.P1ekSe-ZMv3u>div:nth-child(2),.P1ekSe-ZMv3u>div:nth-child(3){background-image:linear-gradient(to right,rgba(255,255,255,0.7),rgba(255,255,255,0.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-webkit-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:'Google Sans',arial,sans-serif;font-size:14px;height:40px;letter-spacing:0.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:0.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:0.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{-webkit-border-radius:20px;border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{-webkit-border-radius:16px;border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{-webkit-border-radius:10px;border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:3px;border-top-left-radius:3px;-webkit-border-bottom-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;justify-content:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:3px;border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:14px;border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:8px;border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;-webkit-flex-direction:row;flex-direction:row;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;flex-grow:1;font-family:'Google Sans',arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{-webkit-box-shadow:none;box-shadow:none;border-color:#d2e3fc;outline:none}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.04)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{-webkit-border-radius:50%;border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:'Roboto';font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:0;border-top-left-radius:0;-webkit-border-bottom-left-radius:0;border-bottom-left-radius:0;-webkit-border-top-right-radius:3px;border-top-right-radius:3px;-webkit-border-bottom-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{-webkit-border-radius:4px;border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}
    /*# sourceURL=/_/gsi/_/ss/k=gsi.gsi.37KUwzZiwNk.L.W.O/am=chE/d=1/rs=AF0KOtXe_8RfoA65Rq3UUlMTkNHQ0LLDfQ/m=gis_client_button_style */</style><script type="text/javascript" src="https://brahma.analyticsvidhya.com/static/CACHE/js/output.855182c52549.js"></script><link id="googleidentityservice" type="text/css" media="all" rel="stylesheet" href="https://accounts.google.com/gsi/style"></head>
    <body class="av-detail-page">
    <main class="w-100 float-left">
    
    <div class="page-header margin-top-fix active">
    <div class="reading-progress-container show">
    <div class="progress-bar" style="width: 100%;"></div>
    </div>
    <div class="container">
    <div class="row">
    <div class="col-md-9 pl-0">
    <h1>How to Get Started with NLP  6 Unique Methods to Perform Tokenization</h1>
    </div>
    <div class="display-content"></div>
    <div class="col-md-3">
    <div id="SocialShare">
    <button type="button">
    <img src="https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/icon/pdf.svg" alt="download" class="download-pdf" title="Download PDF">
    </button>
    <button type="button" class="bookmark bookmark-circle-title"><i class="far fa-bookmark" id="bookmark-article"></i></button>
    <div class="dropdown">
    <button type="button" data-toggle="dropdown" class="dropdown-toggle share" id="socialDropdownMenu" aria-haspopup="true" aria-expanded="false">
    <img src="https://www.analyticsvidhya.com/wp-content/themes/analytics-vidhya/icon/Share.svg" alt="Share">
    </button>
    <ul class="dropdown-menu dropdown-menu-right border-0" aria-labelledby="socialDropdownMenu">
    <li>
    <a target="_blank" data-original-title="Facebook" rel="tooltip" href="http://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F" class="btn" data-placement="left">
    <i class="fab fa-facebook-f btn btn-facebook"></i>
    <span>Facebook</span>
    </a>
    </li>
    <li>
    <a target="_blank" data-original-title="Twitter" rel="tooltip" href="http://twitter.com/share?text=How to Get Started with NLP  6 Unique Methods to Perform Tokenization&amp;url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F" class="btn" data-placement="left">
    <i class="fab fa-twitter btn btn-twitter"></i>
    <span>Twitter</span>
    </a>
    </li>
    <li>
    <a target="_blank" data-original-title="LinkedIn" rel="tooltip" href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F" class="btn" data-placement="left">
    <i class="fab fa-linkedin-in btn btn-linkedin"></i>
    <span>Linkedin</span>
    </a>
    </li>
    <li>
    <a target="_blank" data-original-title="Google+" rel="tooltip" href="https://plus.google.com/share?url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2019%2F07%2Fhow-get-started-nlp-6-unique-ways-perform-tokenization%2F" class="btn" data-placement="left">
    <i class="fab fa-youtube btn btn-google"></i>
    <span>Youtube</span>
    </a>
    </li>
    </ul>
    </div>
    </div>
    </div>
    </div>
    </div>
    </div>
    <div class="container">
    <div class="row">
    <div class="publish-info w-100">
    <a href="https://www.analyticsvidhya.com/blog/author/shubham-singh/">Shubham Singh</a>  July 18, 2019 </div>
    <div class="article-categories">
    <a href="https://www.analyticsvidhya.com/blog/category/intermediate/">Intermediate</a>
    <a href="https://www.analyticsvidhya.com/blog/category/nlp/">NLP</a>
    <a href="https://www.analyticsvidhya.com/blog/category/python-2/">Python</a>
    <a href="https://www.analyticsvidhya.com/blog/category/technique/">Technique</a>
    <a href="https://www.analyticsvidhya.com/blog/category/text/">Text</a>
    <a href="https://www.analyticsvidhya.com/blog/category/unstructured-data/">Unstructured Data</a>
    </div>
    <div class="col-lg-9 col-md-12 col-sm-12 pl-0 pr-0">
    <section class="av-details-page target w-100" id="1">
    <h2 id="h2_1" data-tocid="h2_toc_1" class="target">Overview</h2>
    <ul>
    <li>Looking to get started with Natural Language Processing (NLP)? Heres the perfect first step</li>
    <li>Learn how to perform tokenization  a key aspect to preparing your data for building NLP models</li>
    <li>We present 6 different ways to perform tokenization on text data</li>
    </ul>
    <p>&nbsp;</p>
    <h2 id="h2_2" data-tocid="h2_toc_2" class="target">Introduction</h2>
    <p>Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but arent sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning.</p>
    <p>So how can we manipulate and clean this text data to build a model? The answer lies in the wonderful world of <a href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" target="_blank" rel="noopener noreferrer">Natural Language Processing (NLP)</a>.</p>
    <p>Solving an NLP problem is a multi-stage process. We need to clean the unstructured text data first before we can even think about getting to the modeling stage. Cleaning the data consists of a few key steps:</p>
    <ul>
    <li>Word tokenization</li>
    <li>Predicting parts of speech for each token</li>
    <li>Text lemmatization</li>
    <li>Identifying and removing stop words, and much more.</li>
    </ul>
    <p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg"><img loading="lazy" class="aligncenter wp-image-54700 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg" alt="" width="1020" height="520" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15.jpg 1020w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15-300x153.jpg 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15-768x392.jpg 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Comp-2-0_00_13_15-850x433.jpg 850w" sizes="(max-width: 1020px) 100vw, 1020px"></a></p>
    <p>In this article, we will talk about the very first step  tokenization. We will first see what tokenization is and why its required in NLP. We will then look at six unique ways to perform tokenization in Python.</p>
    <p>This article has no prerequisites. Anyone with an interest in NLP or data science will be able to follow along. If youre looking for an end-to-end resource for learning NLP, you should check out our comprehensive course:</p>
    <ul>
    <li class="section__heading section__heading___be1a0"><a href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" target="_blank" rel="noopener noreferrer">Natural Language Processing using Python</a></li>
    </ul>
    <p>&nbsp;</p>
    <h2 id="h2_3" data-tocid="h2_toc_3" class="target">Table of Contents</h2>
    <ul>
    <li>What is Tokenization in NLP?</li>
    <li>Why is tokenization required?</li>
    <li>Different Methods to Perform Tokenization in Python
    <ul>
    <li>Tokenization using Python split() Function</li>
    <li>Tokenization using Regular Expressions</li>
    <li>Tokenization using NLTK</li>
    <li>Tokenization using Spacy</li>
    <li>Tokenization using Keras</li>
    <li>Tokenization using Gensim</li>
    </ul>
    </li>
    </ul>
    <p>&nbsp;</p>
    <h2 id="h2_4" data-tocid="h2_toc_4" class="target">What is Tokenization in NLP?</h2>
    <p>Tokenization is one of the most common tasks when it comes to working with text data. But what does the term tokenization actually mean?</p>
    <blockquote><p>Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens.</p></blockquote>
    <p>Check out the below image to visualize this definition:</p>
    <p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56.png"><img loading="lazy" class="aligncenter wp-image-54560 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56.png" alt="tokenization nlp" width="959" height="281" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56.png 959w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56-300x88.png 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56-768x225.png 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-50-56-850x249.png 850w" sizes="(max-width: 959px) 100vw, 959px"></a></p>
    <p><span id="__w2_wv5QIgMP4_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">The tokens could be words, numbers or punctuation marks. In tokenization, smaller units are created by locating word boundaries. Wait  what are word boundaries?</span></span></p>
    <p><span id="__w2_wv5QIgMP4_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">These are the ending point of a word and the beginning of the next word.</span></span> <span id="__w2_wv5QIgMP4_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">These tokens are considered as a first step for stemming and lemmatization (the next stage in text preprocessing which we will cover in the next article).</span></span></p>
    <p>Difficult? Do not worry! The 21st century has made learning and knowledge accessibility easy. Any <a href="https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/">Natural Language Processing Course</a> can be used to learn them easily.</p>
    <p>&nbsp;</p>
    <h2 id="h2_5" data-tocid="h2_toc_5" class="target">Why is Tokenization required in NLP?</h2>
    <p>I want you to think about the English language here. Pick up any sentence you can think of and hold that in your mind as you read this section. This will help you understand the importance of tokenization in a much easier manner.</p>
    <p>Before processing a natural language, we need to identify the <em>words</em> that constitute a string of characters. Thats why t<span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">okenization is the most basic step to proceed with NLP (text data). <strong>This is important because the meaning of the text could easily be interpreted by analyzing the words present in the text. </strong></span></span></p>
    <p><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">Lets take an example. Consider the below string:</span></span></p>
    <p style="text-align: center;"><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext"> This is a cat.</span></span></p>
    <p><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">What do you think will happen after we perform tokenization on this string? We get [This, is, a, cat].</span></span></p>
    <p><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">There are numerous uses of doing this. We can use this tokenized form to:</span></span></p>
    <ul>
    <li><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">Count the number of words in the text</span></span></li>
    <li><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">Count the frequency of the word, that is, the number of times a particular word is present</span></span></li>
    </ul>
    <p><span id="__w2_wM0KjEzr5_answer_content" class="inline_editor_value"><span class="ui_qtext_rendered_qtext">And so on. We can extract a lot more information which well discuss in detail in future articles. For now, its time to dive into the meat of this article  the different methods of performing tokenization in NLP.<br>
    </span></span></p>
    <p>&nbsp;</p>
    <h2 id="h2_6" data-tocid="h2_toc_6" class="target">Methods to Perform Tokenization in Python</h2>
    <p>We are going to look at six unique ways we can perform tokenization on text data. I have provided the Python code for each method so you can follow along on your own machine.</p>
    <p>&nbsp;</p>
    <h3>1. Tokenization using Pythons split() function</h3>
    <p>Lets start with the<strong> split()</strong> method as it is the most basic one. It returns a list of strings after breaking the given string by the specified separator. By default, split() breaks a string at each space. We can change the separator to anything. Lets check it out.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/91f15132165f247fac0fd03c5e487a55.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97055094" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-split1-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="split1.py">
            <tbody><tr>
              <td id="file-split1-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-split1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-split1-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-split1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-split1-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-split1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-split1-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-split1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Splits at space </span></td>
            </tr>
            <tr>
              <td id="file-split1-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-split1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span>.<span class="pl-en">split</span>() </td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/91f15132165f247fac0fd03c5e487a55/raw/6f41f9bdf051cad31fed98b1076912e35ab9c7d5/split1.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/91f15132165f247fac0fd03c5e487a55#file-split1-py">
              split1.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/91f15132165f247fac0fd03c5e487a55">Gist</a>.</noscript></div>
    <pre>Output : ['Founded', 'in', '2002,', 'SpaceXs', 'mission', 'is', 'to', 'enable', 'humans', 
              'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 
              'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 'Mars.', 'In', 
              '2008,', 'SpaceXs', 'Falcon', '1', 'became', 'the', 'first', 'privately', 
              'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth.']</pre>
    <p><strong>Sentence Tokenization</strong></p>
    <p>This is similar to word tokenization. Here, we study the structure of sentences in the analysis. A sentence usually ends with a full stop (.), so we can use . as a separator to break the string:</p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/360470f96d6fdab507fdfe44b3594750.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97055119" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-split2-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="split2.py">
            <tbody><tr>
              <td id="file-split2-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-split2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-split2-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-split2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-split2-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-split2-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-split2-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-split2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Splits at '.' </span></td>
            </tr>
            <tr>
              <td id="file-split2-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-split2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span>.<span class="pl-en">split</span>(<span class="pl-s">'. '</span>) </td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/360470f96d6fdab507fdfe44b3594750/raw/b581d2d28f053929a1efdcb83d6e4f1343e83c22/split2.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/360470f96d6fdab507fdfe44b3594750#file-split2-py">
              split2.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/360470f96d6fdab507fdfe44b3594750">Gist</a>.</noscript></div>
    <pre>Output : ['Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring 
               civilization and a multi-planet \nspecies by building a self-sustaining city on 
               Mars', 
              'In 2008, SpaceXs Falcon 1 became the first privately developed \nliquid-fuel 
               launch vehicle to orbit the Earth.']</pre>
    <p>One major drawback of using Pythons <em>split()</em> method is that we can use only one separator at a time. Another thing to note  in word tokenization, <em>split()</em> did not consider punctuation as a separate token.</p>
    <p>&nbsp;</p>
    <h3>2. Tokenization using Regular Expressions (RegEx)</h3>
    <p>First, lets understand what a regular expression is. It is basically a special character sequence that helps you match or find other strings or sets of strings using that sequence as a pattern.</p>
    <p>We can use the <strong>re</strong> library in Python to work with regular expression. This library comes preinstalled with the Python installation package.</p>
    <p>Now, lets perform word tokenization and sentence tokenization keeping RegEx in mind.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/5478a75540e1c900a660d7b5cdeb98f3.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97055282" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-re1-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="re1.py">
            <tbody><tr>
              <td id="file-re1-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-re1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">re</span></td>
            </tr>
            <tr>
              <td id="file-re1-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-re1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-re1-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-re1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-re1-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-re1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-re1-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-re1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">tokens</span> <span class="pl-c1">=</span> <span class="pl-s1">re</span>.<span class="pl-en">findall</span>(<span class="pl-s">"[\w']+"</span>, <span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-re1-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-re1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">tokens</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/5478a75540e1c900a660d7b5cdeb98f3/raw/be57b8ffd7f61f50fcb1bd3ada86c450664422c3/re1.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/5478a75540e1c900a660d7b5cdeb98f3#file-re1-py">
              re1.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/5478a75540e1c900a660d7b5cdeb98f3">Gist</a>.</noscript></div>
    <pre>Output : ['Founded', 'in', '2002', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 
              'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 
              'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 
              'city', 'on', 'Mars', 'In', '2008', 'SpaceX', 's', 'Falcon', '1', 'became', 
              'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 
              'to', 'orbit', 'the', 'Earth']</pre>
    <div class="output">
    <div class="output_area">The <em>re.findall()</em> function finds all the words that match the pattern passed on it and stores it in the list.</div>
    </div>
    <div></div>
    <div>The <code>\w</code> represents any word character which usually means alphanumeric (letters, numbers) and underscore (_). + means any number of times. <strong>So <em>[\w]+</em> signals that the code should find all the alphanumeric characters until any other character is encountered.</strong></div>
    <div></div>
    <div style="text-align: center;"><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01.png"><img loading="lazy" class="aligncenter wp-image-54557 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01.png" alt="regular expressions nlp" width="960" height="538" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01.png 960w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01-300x168.png 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01-768x430.png 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01-850x476.png 850w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-31-01-257x144.png 257w" sizes="(max-width: 960px) 100vw, 960px"></a></div>
    <div></div>
    <div><strong>Sentence Tokenization</strong></div>
    <div></div>
    <div class="output">
    <div class="output_area">To perform sentence tokenization, we can use the <em>re.split()</em> function. This will split the text into sentences by passing a pattern into it.</div>
    <div></div>
    </div>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/36a880cce668bb203a99dd9bc5840650.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97055668" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-re2-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="re2.py">
            <tbody><tr>
              <td id="file-re2-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-re2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">re</span></td>
            </tr>
            <tr>
              <td id="file-re2-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-re2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-re2-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-re2-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on, Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-re2-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-re2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-re2-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-re2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentences</span> <span class="pl-c1">=</span> <span class="pl-s1">re</span>.<span class="pl-en">compile</span>(<span class="pl-s">'[.!?] '</span>).<span class="pl-en">split</span>(<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-re2-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-re2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentences</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/36a880cce668bb203a99dd9bc5840650/raw/0689e632d6af3aefd824ac0b9a52f67c73b2ccd6/re2.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/36a880cce668bb203a99dd9bc5840650#file-re2-py">
              re2.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/36a880cce668bb203a99dd9bc5840650">Gist</a>.</noscript></div>
    <pre>Output : ['Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring 
               civilization and a multi-planet \nspecies by building a self-sustaining city on 
               Mars.', 
              'In 2008, SpaceXs Falcon 1 became the first privately developed \nliquid-fuel 
               launch vehicle to orbit the Earth.']</pre>
    <p>Here, we have an edge over the <em>split()</em> method as we can pass multiple separators at the same time. In the above code, <strong>we used the <em>re.compile()</em> function wherein we passed [.?!]. This means that sentences will split as soon as any of these characters are encountered.</strong></p>
    <p>Interested in reading more about RegEx? The below resources will get you started with Regular Expressions in NLP:</p>
    <ul>
    <li class="entry-title"><a href="https://www.analyticsvidhya.com/blog/2015/06/regular-expression-python/" target="_blank" rel="noopener noreferrer">Beginners Tutorial for Regular Expressions in Python</a></li>
    <li class="entry-title"><a href="https://www.analyticsvidhya.com/blog/2017/03/extracting-information-from-reports-using-regular-expressons-library-in-python/" target="_blank" rel="noopener noreferrer">Extracting information from reports using Regular Expressions Library in Python</a></li>
    </ul>
    <p>&nbsp;</p>
    <h3>3. Tokenization using NLTK</h3>
    <p>Now, this is a library you will appreciate the more you work with text data. NLTK, short for Natural Language ToolKit, is a library written in Python for symbolic and statistical Natural Language Processing.</p>
    <h1 style="text-align: center;"><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55.png"><img loading="lazy" class="aligncenter wp-image-54558 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55.png" alt="NLTK nlp" width="851" height="292" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55.png 851w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55-300x103.png 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55-768x264.png 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-05-13-45-55-850x292.png 850w" sizes="(max-width: 851px) 100vw, 851px"></a></h1>
    <p>You can install NLTK using the below code:</p>
    <pre><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">--user</span> <span class="pre">-U</span> <span class="pre">nltk</span></code></pre>
    <p>NLTK contains a module called <em>tokenize()</em> which further classifies into two sub-categories:</p>
    <ul>
    <li><strong>Word tokenize:</strong> We use the word_tokenize() method to split a sentence into tokens or words</li>
    <li><strong>Sentence tokenize:</strong> We use the sent_tokenize() method to split a document or paragraph into sentences</li>
    </ul>
    <p>Lets see both of these one-by-one.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/4db07456696b5f3ddf91fdafe7da2bad.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97036778" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-word_tokenize-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="word_tokenize.py">
            <tbody><tr>
              <td id="file-word_tokenize-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-word_tokenize-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">tokenize</span> <span class="pl-k">import</span> <span class="pl-s1">word_tokenize</span> </td>
            </tr>
            <tr>
              <td id="file-word_tokenize-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-word_tokenize-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-word_tokenize-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-word_tokenize-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-word_tokenize-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-word_tokenize-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-word_tokenize-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-word_tokenize-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-en">word_tokenize</span>(<span class="pl-s1">text</span>)</td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/4db07456696b5f3ddf91fdafe7da2bad/raw/025a5a3b5ce6e0f86731e7c99cc07eccff138631/word_tokenize.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/4db07456696b5f3ddf91fdafe7da2bad#file-word_tokenize-py">
              word_tokenize.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/4db07456696b5f3ddf91fdafe7da2bad">Gist</a>.</noscript></div>
    <pre>Output: ['Founded', 'in', '2002', ',', 'SpaceX', '', 's', 'mission', 'is', 'to', 'enable', 
             'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 
             'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 
             'Mars', '.', 'In', '2008', ',', 'SpaceX', '', 's', 'Falcon', '1', 'became', 
             'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 
             'to', 'orbit', 'the', 'Earth', '.']</pre>
    <div class="output output_scroll">
    <div class="output_area">Notice how NLTK is considering punctuation as a token? Hence for future tasks, we need to remove the punctuations from the initial list.</div>
    <div></div>
    </div>
    <p><strong>Sentence Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/2f09e9750c1deefa9332d87d1ffa9ac9.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97054819" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-sent_tokenize-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="sent_tokenize.py">
            <tbody><tr>
              <td id="file-sent_tokenize-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-sent_tokenize-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">tokenize</span> <span class="pl-k">import</span> <span class="pl-s1">sent_tokenize</span></td>
            </tr>
            <tr>
              <td id="file-sent_tokenize-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-sent_tokenize-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-sent_tokenize-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-sent_tokenize-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-sent_tokenize-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-sent_tokenize-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-sent_tokenize-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-sent_tokenize-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-en">sent_tokenize</span>(<span class="pl-s1">text</span>)</td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/2f09e9750c1deefa9332d87d1ffa9ac9/raw/ad85633b911464d99424448adb58ee69f54ae2ea/sent_tokenize.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/2f09e9750c1deefa9332d87d1ffa9ac9#file-sent_tokenize-py">
              sent_tokenize.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/2f09e9750c1deefa9332d87d1ffa9ac9">Gist</a>.</noscript></div>
    <pre>Output: ['Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring 
              civilization and a multi-planet \nspecies by building a self-sustaining city on 
              Mars.', 
             'In 2008, SpaceXs Falcon 1 became the first privately developed \nliquid-fuel 
              launch vehicle to orbit the Earth.']</pre>
    <p>&nbsp;</p>
    <h3>4. Tokenization using the spaCy library</h3>
    <p>I love the spaCy library. I cant remember the last time I didnt use it when I was working on an NLP project. It is just that useful.</p>
    <p>spaCy is an <strong>open-source library</strong> for advanced <a href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" target="_blank" rel="noopener noreferrer"><strong>Natural Language Processing</strong> (NLP)</a>. It supports over 49+ languages and provides state-of-the-art computation speed.</p>
    <p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy.jpg"><img loading="lazy" class="aligncenter size-full wp-image-53381" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy.jpg" alt="" width="1200" height="630" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy.jpg 1200w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy-300x158.jpg 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy-768x403.jpg 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/spaCy-850x446.jpg 850w" sizes="(max-width: 1200px) 100vw, 1200px"></a></p>
    <p>To install Spacy in Linux:</p>
    <pre>pip install -U spacy
    python -m spacy download en</pre>
    <p>To install it on other operating systems, go through <a href="https://spacy.io/usage" target="_blank" rel="noopener noreferrer">this link</a>.</p>
    <p>So, lets see how we can utilize the awesomeness of spaCy to perform tokenization. We will use <em>spacy.lang.en</em> which supports the English language.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/aa51ec4f1f19ef11a16d65b51d1b7c0d.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97055989" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-spacy1-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="spacy1.py">
            <tbody><tr>
              <td id="file-spacy1-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-spacy1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">spacy</span>.<span class="pl-s1">lang</span>.<span class="pl-s1">en</span> <span class="pl-k">import</span> <span class="pl-v">English</span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-spacy1-py-LC2" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-spacy1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Load English tokenizer, tagger, parser, NER and word vectors</span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-spacy1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">nlp</span> <span class="pl-c1">=</span> <span class="pl-v">English</span>()</td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-spacy1-py-LC5" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-spacy1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L7" class="blob-num js-line-number js-code-nav-line-number" data-line-number="7"></td>
              <td id="file-spacy1-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L8" class="blob-num js-line-number js-code-nav-line-number" data-line-number="8"></td>
              <td id="file-spacy1-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L9" class="blob-num js-line-number js-code-nav-line-number" data-line-number="9"></td>
              <td id="file-spacy1-py-LC9" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L10" class="blob-num js-line-number js-code-nav-line-number" data-line-number="10"></td>
              <td id="file-spacy1-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-c">#  "nlp" Object is used to create documents with linguistic annotations.</span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L11" class="blob-num js-line-number js-code-nav-line-number" data-line-number="11"></td>
              <td id="file-spacy1-py-LC11" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">my_doc</span> <span class="pl-c1">=</span> <span class="pl-en">nlp</span>(<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L12" class="blob-num js-line-number js-code-nav-line-number" data-line-number="12"></td>
              <td id="file-spacy1-py-LC12" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L13" class="blob-num js-line-number js-code-nav-line-number" data-line-number="13"></td>
              <td id="file-spacy1-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Create list of word tokens</span></td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L14" class="blob-num js-line-number js-code-nav-line-number" data-line-number="14"></td>
              <td id="file-spacy1-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">token_list</span> <span class="pl-c1">=</span> []</td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L15" class="blob-num js-line-number js-code-nav-line-number" data-line-number="15"></td>
              <td id="file-spacy1-py-LC15" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">token</span> <span class="pl-c1">in</span> <span class="pl-s1">my_doc</span>:</td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L16" class="blob-num js-line-number js-code-nav-line-number" data-line-number="16"></td>
              <td id="file-spacy1-py-LC16" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">token_list</span>.<span class="pl-en">append</span>(<span class="pl-s1">token</span>.<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy1-py-L17" class="blob-num js-line-number js-code-nav-line-number" data-line-number="17"></td>
              <td id="file-spacy1-py-LC17" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">token_list</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/aa51ec4f1f19ef11a16d65b51d1b7c0d/raw/73a340125bf7d4ff189bfe863f6101d0ec8a5635/spacy1.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/aa51ec4f1f19ef11a16d65b51d1b7c0d#file-spacy1-py">
              spacy1.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/aa51ec4f1f19ef11a16d65b51d1b7c0d">Gist</a>.</noscript></div>
    <div class="output_subarea output_text output_stream output_stdout">
    <pre>Output : ['Founded', 'in', '2002', ',', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 
              'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 
              'multi', '-', 'planet', '\n', 'species', 'by', 'building', 'a', 'self', '-', 
              'sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', 's', 
              'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', '\n', 
              'liquid', '-', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']</pre>
    </div>
    <p>&nbsp;</p>
    <p><strong>Sentence Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/e0583c56f55f392414fd104f02efc2d4.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97056018" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-spacy2-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="spacy2.py">
            <tbody><tr>
              <td id="file-spacy2-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-spacy2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">spacy</span>.<span class="pl-s1">lang</span>.<span class="pl-s1">en</span> <span class="pl-k">import</span> <span class="pl-v">English</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-spacy2-py-LC2" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-spacy2-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Load English tokenizer, tagger, parser, NER and word vectors</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-spacy2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">nlp</span> <span class="pl-c1">=</span> <span class="pl-v">English</span>()</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-spacy2-py-LC5" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-spacy2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Create the pipeline 'sentencizer' component</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L7" class="blob-num js-line-number js-code-nav-line-number" data-line-number="7"></td>
              <td id="file-spacy2-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sbd</span> <span class="pl-c1">=</span> <span class="pl-s1">nlp</span>.<span class="pl-en">create_pipe</span>(<span class="pl-s">'sentencizer'</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L8" class="blob-num js-line-number js-code-nav-line-number" data-line-number="8"></td>
              <td id="file-spacy2-py-LC8" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L9" class="blob-num js-line-number js-code-nav-line-number" data-line-number="9"></td>
              <td id="file-spacy2-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Add the component to the pipeline</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L10" class="blob-num js-line-number js-code-nav-line-number" data-line-number="10"></td>
              <td id="file-spacy2-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">nlp</span>.<span class="pl-en">add_pipe</span>(<span class="pl-s1">sbd</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L11" class="blob-num js-line-number js-code-nav-line-number" data-line-number="11"></td>
              <td id="file-spacy2-py-LC11" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L12" class="blob-num js-line-number js-code-nav-line-number" data-line-number="12"></td>
              <td id="file-spacy2-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L13" class="blob-num js-line-number js-code-nav-line-number" data-line-number="13"></td>
              <td id="file-spacy2-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L14" class="blob-num js-line-number js-code-nav-line-number" data-line-number="14"></td>
              <td id="file-spacy2-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L15" class="blob-num js-line-number js-code-nav-line-number" data-line-number="15"></td>
              <td id="file-spacy2-py-LC15" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L16" class="blob-num js-line-number js-code-nav-line-number" data-line-number="16"></td>
              <td id="file-spacy2-py-LC16" class="blob-code blob-code-inner js-file-line"><span class="pl-c">#  "nlp" Object is used to create documents with linguistic annotations.</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L17" class="blob-num js-line-number js-code-nav-line-number" data-line-number="17"></td>
              <td id="file-spacy2-py-LC17" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">doc</span> <span class="pl-c1">=</span> <span class="pl-en">nlp</span>(<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L18" class="blob-num js-line-number js-code-nav-line-number" data-line-number="18"></td>
              <td id="file-spacy2-py-LC18" class="blob-code blob-code-inner js-file-line">
    </td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L19" class="blob-num js-line-number js-code-nav-line-number" data-line-number="19"></td>
              <td id="file-spacy2-py-LC19" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># create list of sentence tokens</span></td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L20" class="blob-num js-line-number js-code-nav-line-number" data-line-number="20"></td>
              <td id="file-spacy2-py-LC20" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sents_list</span> <span class="pl-c1">=</span> []</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L21" class="blob-num js-line-number js-code-nav-line-number" data-line-number="21"></td>
              <td id="file-spacy2-py-LC21" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sent</span> <span class="pl-c1">in</span> <span class="pl-s1">doc</span>.<span class="pl-s1">sents</span>:</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L22" class="blob-num js-line-number js-code-nav-line-number" data-line-number="22"></td>
              <td id="file-spacy2-py-LC22" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">sents_list</span>.<span class="pl-en">append</span>(<span class="pl-s1">sent</span>.<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-spacy2-py-L23" class="blob-num js-line-number js-code-nav-line-number" data-line-number="23"></td>
              <td id="file-spacy2-py-LC23" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sents_list</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/e0583c56f55f392414fd104f02efc2d4/raw/fffcbcb669d7ce02193b991565dc5bfc9a003b79/spacy2.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/e0583c56f55f392414fd104f02efc2d4#file-spacy2-py">
              spacy2.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/e0583c56f55f392414fd104f02efc2d4">Gist</a>.</noscript></div>
    <pre>Output : ['Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring 
               civilization and a multi-planet \nspecies by building a self-sustaining city on 
               Mars.', 
              'In 2008, SpaceXs Falcon 1 became the first privately developed \nliquid-fuel 
               launch vehicle to orbit the Earth.']</pre>
    <p>spaCy is quite fast as compared to other libraries while performing NLP tasks (yes, even NLTK). I encourage you to listen to the below DataHack Radio podcast to know the story behind how spaCy was created and where you can use it:</p>
    <ul>
    <li class="entry-title"><a href="https://www.analyticsvidhya.com/blog/2019/06/datahack-radio-ines-montani-matthew-honnibal-brains-behind-spacy/?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" target="_blank" rel="noopener noreferrer">DataHack Radio #23: Ines Montani and Matthew Honnibal  The Brains behind spaCy</a></li>
    </ul>
    <p>And heres an in-depth tutorial to get you started with spaCy:</p>
    <ul>
    <li><a href="https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/?utm_source=blog&amp;utm_medium=how-get-started-nlp-6-unique-ways-perform-tokenization" target="_blank" rel="noopener noreferrer">Natural Language Processing Made Easy  using SpaCy (&ZeroWidthSpace;in Python)</a></li>
    </ul>
    <p>&nbsp;</p>
    <h3>5. Tokenization using Keras</h3>
    <p>Keras! One of the hottest deep learning frameworks in the industry right now. It is an open-source neural network library for Python. Keras is super easy to use and can also run on top of TensorFlow.</p>
    <p>In the NLP context, we can use Keras for cleaning the unstructured text data that we typically collect.</p>
    <p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization.png"><img loading="lazy" class="aligncenter size-full wp-image-55183" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization.png" alt="keras_tokenization" width="1200" height="348" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization.png 1200w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization-300x87.png 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization-768x223.png 768w, https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/keras_tokenization-850x247.png 850w" sizes="(max-width: 1200px) 100vw, 1200px"></a></p>
    <p>You can install Keras on your machine using just one line of code:</p>
    <pre><span id="pip-command">pip install Keras</span></pre>
    <p>Lets get cracking. To perform word tokenization using Keras, we use the <em>text_to_word_sequence</em> method from the <em>keras.preprocessing.text</em> class.</p>
    <p>Lets see Keras in action.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/2fbb3472d4af39b5c6d8235943dd4e8d.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97056812" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-keras1-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="keras1.py">
            <tbody><tr>
              <td id="file-keras1-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-keras1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">keras</span>.<span class="pl-s1">preprocessing</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-s1">text_to_word_sequence</span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-keras1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># define</span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-keras1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-keras1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-keras1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-keras1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># tokenize</span></td>
            </tr>
            <tr>
              <td id="file-keras1-py-L7" class="blob-num js-line-number js-code-nav-line-number" data-line-number="7"></td>
              <td id="file-keras1-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">result</span> <span class="pl-c1">=</span> <span class="pl-en">text_to_word_sequence</span>(<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-keras1-py-L8" class="blob-num js-line-number js-code-nav-line-number" data-line-number="8"></td>
              <td id="file-keras1-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">result</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/2fbb3472d4af39b5c6d8235943dd4e8d/raw/dea5ebd58cd544e946a9f318bce2dd2802fea1ff/keras1.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/2fbb3472d4af39b5c6d8235943dd4e8d#file-keras1-py">
              keras1.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/2fbb3472d4af39b5c6d8235943dd4e8d">Gist</a>.</noscript></div>
    <pre>Output : ['founded', 'in', '2002', 'spacexs', 'mission', 'is', 'to', 'enable', 'humans', 
              'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 
              'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 
              'mars', 'in', '2008', 'spacexs', 'falcon', '1', 'became', 'the', 'first', 
              'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 
              'the', 'earth']</pre>
    <p>Keras lowers the case of all the alphabets before tokenizing them. That saves us quite a lot of time as you can imagine!</p>
    <p>&nbsp;</p>
    <h3>6. Tokenization using Gensim</h3>
    <p>The final tokenization method we will cover here is using the Gensim library. <strong>It is an open-source library for unsupervised topic modeling and natural language processing</strong> and is designed to automatically extract semantic topics from a given document.</p>
    <p>Heres how you can install Gensim:</p>
    <pre><span id="pip-command">pip install gensim</span></pre>
    <p>We can use the <em>gensim.utils</em> class to import the <em>tokenize</em> method for performing word tokenization.</p>
    <p><strong>Word Tokenization</strong></p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/6d56faa5c742e6d2d58c865029386e8e.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97067705" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-gensim1-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="gensim1.py">
            <tbody><tr>
              <td id="file-gensim1-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-gensim1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">gensim</span>.<span class="pl-s1">utils</span> <span class="pl-k">import</span> <span class="pl-s1">tokenize</span></td>
            </tr>
            <tr>
              <td id="file-gensim1-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-gensim1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-gensim1-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-gensim1-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-gensim1-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-gensim1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-gensim1-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-gensim1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-en">list</span>(<span class="pl-en">tokenize</span>(<span class="pl-s1">text</span>))</td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/6d56faa5c742e6d2d58c865029386e8e/raw/e0eaaed950d02fb152de6954c9fbaa78379e723f/gensim1.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/6d56faa5c742e6d2d58c865029386e8e#file-gensim1-py">
              gensim1.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/6d56faa5c742e6d2d58c865029386e8e">Gist</a>.</noscript></div>
    <pre>Outpur : ['Founded', 'in', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 
              'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 
              'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 
              'In', 'SpaceX', 's', 'Falcon', 'became', 'the', 'first', 'privately', 
              'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 
              'Earth']</pre>
    <p><strong>Sentence Tokenization</strong></p>
    <p>To perform sentence tokenization, we use the <em>split_sentences</em> method from the <em>gensim.summerization.texttcleaner</em> class:</p>
    <div class="oembed-gist"><script src="https://gist.github.com/shubham-singh-ss/3f0def7c4d910586c1f5692b26bfb85b.js" type="text/javascript"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-ff75a167df5efbfedb0e388793ca9fe7.css"><div id="gist97067711" class="gist">
        <div class="gist-file" translate="no">
          <div class="gist-data">
            <div class="js-gist-file-update-container js-task-list-container file-box">
      <div id="file-gensim2-py" class="file my-2">
        
      <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
    
          
    <div class="js-check-bidi blob-code-content">
      <template class="js-file-alert-template">
      <div data-view-component="true" class="flash flash-warn flash-full d-flex flex-items-center">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
      
        <span>
          This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
          <a href="https://github.co/hiddenchars" target="_blank">Learn more about bidirectional Unicode characters</a>
        </span>
    
    
      <div data-view-component="true" class="flash-action">        <a href="{{ revealButtonHref }}" data-view-component="true" class="btn-sm btn">
      
      Show hidden characters
      
    
    </a>
    </div>
    </div></template>
    <template class="js-line-alert-template">
      <span aria-label="This line has hidden Unicode characters" data-view-component="true" class="bidi-line-alert tooltipped tooltipped-e">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
        <path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path>
    </svg>
    </span></template>
    
      <table class="highlight tab-size js-file-line-container js-code-nav-container js-tagsearch-file" data-tab-size="8" data-paste-markdown-skip="" data-tagsearch-lang="Python" data-tagsearch-path="gensim2.py">
            <tbody><tr>
              <td id="file-gensim2-py-L1" class="blob-num js-line-number js-code-nav-line-number" data-line-number="1"></td>
              <td id="file-gensim2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">gensim</span>.<span class="pl-s1">summarization</span>.<span class="pl-s1">textcleaner</span> <span class="pl-k">import</span> <span class="pl-s1">split_sentences</span></td>
            </tr>
            <tr>
              <td id="file-gensim2-py-L2" class="blob-num js-line-number js-code-nav-line-number" data-line-number="2"></td>
              <td id="file-gensim2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"""Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring civilization and a multi-planet </span></td>
            </tr>
            <tr>
              <td id="file-gensim2-py-L3" class="blob-num js-line-number js-code-nav-line-number" data-line-number="3"></td>
              <td id="file-gensim2-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s">species by building a self-sustaining city on Mars. In 2008, SpaceXs Falcon 1 became the first privately developed </span></td>
            </tr>
            <tr>
              <td id="file-gensim2-py-L4" class="blob-num js-line-number js-code-nav-line-number" data-line-number="4"></td>
              <td id="file-gensim2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s">liquid-fuel launch vehicle to orbit the Earth."""</span></td>
            </tr>
            <tr>
              <td id="file-gensim2-py-L5" class="blob-num js-line-number js-code-nav-line-number" data-line-number="5"></td>
              <td id="file-gensim2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">result</span> <span class="pl-c1">=</span> <span class="pl-en">split_sentences</span>(<span class="pl-s1">text</span>)</td>
            </tr>
            <tr>
              <td id="file-gensim2-py-L6" class="blob-num js-line-number js-code-nav-line-number" data-line-number="6"></td>
              <td id="file-gensim2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">result</span></td>
            </tr>
      </tbody></table>
    </div>
    
    
      </div>
    
      </div>
    </div>
    
          </div>
          <div class="gist-meta">
            <a href="https://gist.github.com/shubham-singh-ss/3f0def7c4d910586c1f5692b26bfb85b/raw/c07c45fd812d5854299f8b3937ac94c003a8152a/gensim2.py" style="float:right">view raw</a>
            <a href="https://gist.github.com/shubham-singh-ss/3f0def7c4d910586c1f5692b26bfb85b#file-gensim2-py">
              gensim2.py
            </a>
            hosted with  by <a href="https://github.com">GitHub</a>
          </div>
        </div>
    </div>
    <noscript>View the code on <a href="https://gist.github.com/shubham-singh-ss/3f0def7c4d910586c1f5692b26bfb85b">Gist</a>.</noscript></div>
    <pre>Output : ['Founded in 2002, SpaceXs mission is to enable humans to become a spacefaring 
               civilization and a multi-planet ', 
              'species by building a self-sustaining city on Mars.', 
              'In 2008, SpaceXs Falcon 1 became the first privately developed ', 
              'liquid-fuel launch vehicle to orbit the Earth.']</pre>
    <p>You might have noticed that Gensim is quite strict with punctuation. It splits whenever a punctuation is encountered. In sentence splitting as well, Gensim tokenized the text on encountering \n while other libraries ignored it.</p>
    <p>&nbsp;</p>
    <h2 id="h2_7" data-tocid="h2_toc_7" class="target">End Notes</h2>
    <p>Tokenization is a critical step in the overall NLP pipeline. We cannot simply jump into the model building part without cleaning the text first.</p>
    <p>In this article, we saw six different methods of tokenization (word as well as a sentence) from a given text. There are other ways as well but these are good enough to get you started on the topic.</p>
    <p>Ill be covering other text cleaning steps like removing stopwords, part-of-speech tagging, and recognizing named entities in my future posts. Till then, keep learning!</p>
     </section>
    
    
    </div>
    <div class="col-lg-3 col-md-12 col-sm-12">
    <div class="widget_text display-for-right mb-3 right-sidebar-1" id="custom_html-5"><div class="textwidget custom-html-widget"><a href="https://blackbelt.analyticsvidhya.com/bundles/data-science-online-course-training-projects-certification-program?utm_source=blog&amp;utm_medium=side_banner_international"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/11/ds_jobs.png"></a></div></div><div class="widget_text display-for-right mb-3 right-sidebar-2 d-none" id="custom_html-6"><div class="textwidget custom-html-widget"></div></div> <script type="text/javascript">
     $(document).ready(function(){
        $.get("https://www.analyticsvidhya.com/back-channel/check-country.php", function(data){
          if (data == "0") 
            $(".right-sidebar-1").removeClass("d-none");
          else if (data == "1")
            $(".right-sidebar-2").removeClass("d-none");
        });
    });
    </script>
    <div class="detail-page-side-bar change-to-sticky active">
    <aside id="navTarget">
    <h6>Table of contents</h6>
    <ul class="toc nav navbar-nav">
    <li><a href="#h2_1" class="h2_toc" id="h2_toc_1">Overview</a></li><li><a href="#h2_2" class="h2_toc" id="h2_toc_2">Introduction</a></li><li><a href="#h2_3" class="h2_toc" id="h2_toc_3">Table of Contents</a></li><li><a href="#h2_4" class="h2_toc" id="h2_toc_4">What is Tokenization in NLP?</a></li><li><a href="#h2_5" class="h2_toc" id="h2_toc_5">Why is Tokenization required in NLP?</a></li><li><a href="#h2_6" class="h2_toc" id="h2_toc_6">Methods to Perform Tokenization in Python</a></li><li><a href="#h2_7" class="h2_toc active" id="h2_toc_7">End Notes</a></li></ul>
    </aside>
    </div>
    </div>
    </div>
    </div>
    </main>
    </body></html>